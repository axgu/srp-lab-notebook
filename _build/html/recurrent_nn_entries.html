
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Recurrent Neural Network &#8212; My Project</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My Project</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prep Work
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="prep/deep_learning/deep_learning.html">
   Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/deep_learning/dl_intro_notes.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/deep_learning/dl_tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/deep_learning/dl_tutorial1_code.html">
     Tutorial 1 Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/deep_learning/dl_tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="prep/log_reg/logistic_regression.html">
   Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/log_reg/diabetes-logreg.html">
     Diabetes Prediction with Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="prep/log_reg/diabetes-summary.html">
     Diabetes Prediction Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  HCP Dataset
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="hcp_data/hcp_summary.html">
   HCP Dataset
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="hcp_data/data.html">
     Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="hcp_data/hcp_logreg.html">
   HCP Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="hcp_data/hcp_logreg_indivtime.html">
     Logistic Regression - ROI Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hcp_data/hcp_logreg_permtest.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="multiple_inference.html">
   Multiple Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="hcp_data/ff_summary.html">
   Feedforward Summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hcp_data/ff.html">
   Feedforward Neural Network
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hcp_data/ff_attention_summary.html">
   Feedforward Attention Summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hcp_data/ff_attention.html">
   Feedforward with Attention
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  RNN
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="recurrent_nn.html">
   Recurrent Neural Network Notes
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Attention
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="hcp_data/attention_methods.html">
   Attention Methods
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/recurrent_nn_entries.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Recurrent Neural Network</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="recurrent-neural-network">
<h1>Recurrent Neural Network<a class="headerlink" href="#recurrent-neural-network" title="Permalink to this headline">#</a></h1>
<p><strong>Recurrent Neural Networks</strong></p>
<p><em>07/11/2022, 8:40 am</em></p>
<p>Synopsis: I will learn about LSTM models and apply one to the HCP dataset.</p>
<p>Data: I sent Ms. Bosse an email updating her with my progress for the first few weeks of my internship. I also took notes on recurrent neural networks, and more specifically, Gated Recurrent Units. I also read about LSTMs, another RNN architecture. Finally, I looked into implementing an RNN using different Python libraries, including Pytorch, Tensorflow, and sklearn.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="recurrent_nn.html"><span class="doc std std-doc">Recurrent Neural Network Notes</span></a></p></li>
</ul>
<p><em>5:12 pm, 512 minutes</em></p>
<hr class="docutils" />
<p><strong>RNN Data Processing</strong></p>
<p><em>07/12/2022, 9:02 am</em></p>
<p>Synopsis: I will apply a GRU network to the HCP dataset.</p>
<p>Data: I learned about specific parameters and requirements with implementing a GRU model using Tensorflow and Pytorch. I also wrote code to split the HCP dataset into training and testing dictionaries. Then, I wrote a function that reshaped these dictionaries into 3D X (input) arrays of shape (batch x time x features) and 2D y (output) arrays of shape (batch x time). Instead of using all possible time points, I limited the sequence length to the first 90 time points. However, because some movie clips were sampled for times shorter than 90 seconds, I learned about padding and masking the data.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/rnn_data_prep.html"><span class="doc std std-doc">RNN Data Prep Program</span></a></p></li>
</ul>
<p><em>5:26 pm, 504 minutes</em></p>
<hr class="docutils" />
<p><strong>RNN Training</strong></p>
<p><em>07/13/2022, 9:00 am</em></p>
<p>Synopsis: I will apply a GRU network to the HCP dataset.</p>
<p>Data: I built a GRU model using Tensorflow/Keras with a Masking layer, GRU layer, and TimeDistributed/Dense layer. The final layer was used to allow separate time calculations and also apply the softmax activation function to the previous outputs, since labels were one-hot encoded into 15D vectors. The model was trained with X and y training data, batch_size = 32, epoch = 50, and validation_split = 0.2. It was then used to predict clips of the input test data. Accuracy functions were written to evaluate the model, though the results indicate that there were some issues with masking, since there is a noticeable decrease in performance for time points after 65 seconds and 84 seconds, which is when overcome and testretest clips end, respectively.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/rnn_data_prep.html"><span class="doc std std-doc">RNN Data Prep Program</span></a></p></li>
</ul>
<p><em>5:01 pm, 481 minutes</em></p>
<hr class="docutils" />
<p><strong>RNN Masking and Evaluation</strong></p>
<p><em>07/14/2022, 8:31 am</em></p>
<p>Synopsis: I will learn more about masking and padding data and evaluate the performance of the neural network.</p>
<p>Data: I learned about masking and padding in Keras, and tried to apply it to my model. An issue I encountered was that the Keras frameworks skip over the masked time step for all samples, not just the padded ones. I also corrected my accuracy function. Finally, I worked on optimizing the performance of the LSTM by tuning hyperparameters, such as changing batch size, epochs, dropout rate, etc.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/rnn_data_prep.html"><span class="doc std std-doc">RNN Data Prep Program</span></a></p></li>
</ul>
<p><em>4:40 pm, 489 minutes</em></p>
<hr class="docutils" />
<p><strong>RNN with PyTorch</strong></p>
<p><em>07/15/2022, 9:15 am</em></p>
<p>Synopsis: I will work on fixing the masking issue of the neural network.</p>
<p>Data: I learned about implementing neural networks with PyTorch instead of Tensorflow.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">LSTM PyTorch Model (.py)</span></p></li>
</ul>
<p><em>2:33 pm, 318 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Methods</strong></p>
<p><em>07/18/2022, 8:50 am</em></p>
<p>Synopsis: I will learn about attention methods.</p>
<p>Data: I learned about sequence to sequence models, specifically about encoder decoder architectures. I also looked into LSTM models to understand how they worked. Then, I learned about the bottleneck problem in standard encoder decoder models and the solution provided by attention. I looked into several attention mechanisms within seq2seq problems, as well as a basic overview of self-attention.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/attention_methods.html"><span class="doc std std-doc">Attention Methods Notes</span></a></p></li>
</ul>
<p><em>5:50 pm, 540 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model</strong></p>
<p><em>07/19/2022, 9:00 am</em></p>
<p>Synopsis: I will implement an attention model.</p>
<p>Data: I worked on adding figures to my attention methods notes. Then, I started working in Python with PyTorch to build an encoder class and a decoder class.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/attention_methods.html"><span class="doc std std-doc">Attention Methods Notes</span></a></p></li>
<li><p><span class="xref myst">Attention Model (.py)</span></p></li>
</ul>
<p><em>5:00 pm, 480 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model</strong></p>
<p><em>07/20/2022, 9:00 am</em></p>
<p>Synopsis: I will implement an attention model.</p>
<p>Data: I finished building the encoder, decoder, and attention classes in PyTorch. Then, I worked on preprocessing the dataset into training/testing and input/output data. I also created functions for padding the arrays and vectorizing the movie clip labels. I wrote code to train the model that incorporates the attention mechanism. Finally, I looked into creating masks with PyTorch, and will implement that, as well as model evaluation, tomorrow.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">Attention Model (.py)</span></p></li>
<li><p><span class="xref myst">Data Prep (.py)</span></p></li>
</ul>
<p><em>5:33 pm, 513 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model</strong></p>
<p><em>07/21/2022, 8:00 am</em></p>
<p>Synopsis: I will continue working on my attention model.</p>
<p>Data: I fixed errors within my encoder and decoder classes. I also built an LSTM  model in PyTorch, as well as train and test methods. An issue with my LSTM model when I try to train it is that the loss stays constant over all epochs.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">Attention Model (.py)</span></p></li>
<li><p><span class="xref myst">Model Evaluation (.py)</span></p></li>
</ul>
<p><em>7:30 pm, 690 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model Masking</strong></p>
<p><em>07/25/2022, 9:00 am</em></p>
<p>Synopsis: I will continue working on my attention model.</p>
<p>Data: I worked on adding padding and masking to the data in my LSTM and encoder-decoder attention model. I was also able to fix the issue with my LSTM model where the training loss was not decreasing by transposing the output from the LSTM and the actual y arrays from (batch size x sequence length x class) to (batch size x class x sequence length). Then I continued training the models.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">Attention Model (.py)</span></p></li>
</ul>
<p><em>6:15 pm, 555 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model Training</strong></p>
<p><em>07/26/2022, 8:30 am</em></p>
<p>Synopsis: I will continue working on my attention model.</p>
<p>Data: I continued training my LSTM and Seq2Seq models, experimenting with learning rate and epoch size. I also saved them to my local disk and plotted the resulting accuracies for comparison.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">Attention Model (.py)</span></p></li>
<li><p><span class="xref myst">LSTM Model (.py)</span></p></li>
</ul>
<p><em>6:25 pm, 595 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model Permutation Test</strong></p>
<p><em>07/27/2022, 9:25 am</em></p>
<p>Synopsis: I will perform a permutation test on my LSTM and Seq2Seq attention model.</p>
<p>Data: I wrote functions to shuffle each feature along the time steps in a batch. I then ran a permutation test with 100 resamples and plotted a comparison of accuracy between logistic regression, LSTM, and attention performance.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">RNN Permutation Test Code (.py)</span></p></li>
<li><p><a class="reference internal" href="hcp_data/attention-book.html"><span class="doc std std-doc">Attention Model</span></a></p></li>
<li><p><a class="reference internal" href="hcp_data/lstm-book.html"><span class="doc std std-doc">LSTM Model</span></a></p></li>
<li><p><a class="reference internal" href="hcp_data/hcp_plot.html"><span class="doc std std-doc">Visual Model Comparison</span></a></p></li>
</ul>
<p><em>5:20 pm, 475 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model Analysis</strong></p>
<p><em>07/28/2022, 8:30 am</em></p>
<p>Synopsis: I will summarize what I have implemented.</p>
<p>Data: The permutation test for the attention Seq2Seq model indicated around 80% accuracy, which is unreasonably high. So, I worked on trying to “break” my model. Each method I utilized was performed 3 times. I tested by randomizing labels for each (batch, time step), which yielded an 8% accuracy for all time steps, and randomizing labels for each batch but remaining the same for all time steps, which yielded a 22% accuracy. I then tried re-running the permutation test (i.e. shuffling the data across time steps for each feature). Afterward, I tried randomly generating input feature data from a normal distribution. Both of these evaluations also yielded approximately an 80% accuracy for all time steps.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">RNN Permutation Test Code (.py)</span></p></li>
<li><p><a class="reference internal" href="hcp_data/attention-book.html"><span class="doc std std-doc">Attention Model</span></a></p></li>
</ul>
<p><em>7:02 pm, 632 minutes</em></p>
<hr class="docutils" />
<p><strong>Attention Model Summary</strong></p>
<p><em>07/29/2022, 8:39 am</em></p>
<p>Synopsis: I will continue analyzing why my attention model has such a high performance with permuted samples.</p>
<p>Data:</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">RNN Permutation Test Code (.py)</span></p></li>
<li><p><a class="reference internal" href="hcp_data/attention-book.html"><span class="doc std std-doc">Attention Model</span></a></p></li>
</ul>
<p><em>4:00 pm, 441 minutes</em></p>
<hr class="docutils" />
<p><strong>Neural Networks</strong></p>
<p><em>08/01/2022, 8:27 am</em></p>
<p>Synopsis: I will continue analyzing why my attention model has such a high performance with random inputs.</p>
<p>Data: I learned more about attention mechanism through a meeting with mentors. I also watched videos and read about how neural networks work and backpropagation.</p>
<p><em>6:00 pm, 573 minutes</em></p>
<hr class="docutils" />
<p><strong>Feedforward Network</strong></p>
<p><em>08/02/2022, 8:53 am</em></p>
<p>Synopsis: I will build a feedforward neural network.</p>
<p>Data: I built, trained, and evaluated a feedforward neural network in PyTorch that considers time steps blindly. I also tried adding the attention mechanism discussed in the meeting yesterday to a recurrent neural network and trained the model.</p>
<p>Files:</p>
<ul class="simple">
<li><p><span class="xref myst">RNN Permutation Test Code (.py)</span></p></li>
<li><p><a class="reference internal" href="hcp_data/attention-book.html"><span class="doc std std-doc">Attention Model</span></a></p></li>
</ul>
<p><em>6:20 pm, 567 minutes</em></p>
<hr class="docutils" />
<p><strong>Feedforward with Attention</strong></p>
<p><em>08/03/2022, 8:38 am</em></p>
<p>Synopsis: I will summarize what I did with the feedforward neural network.</p>
<p>Data: I wrote a summary of my work with the feedforward neural network. I provided details about handling the dataset, architecture specification, training, and evaluating model performance. I had another meeting with my mentors to discuss adding an attention layer to a feedforward network. Then I tried implementing what was discussed. However, when I tried training the model, every epoch took over an hour and a half and the loss for several iterations was outputted as infinity.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/ff_summary.html"><span class="doc std std-doc">Feedforward Network Summary</span></a></p></li>
<li><p><a class="reference internal" href="hcp_data/ff_attention.html"><span class="doc std std-doc">Feedforward Attention</span></a></p></li>
</ul>
<p><em>5:30 pm, 532 minutes</em></p>
<hr class="docutils" />
<p><strong>Feedforward with Attention</strong></p>
<p><em>08/04/2022, 8:48 am</em></p>
<p>Synopsis: I will continue training the feedforward/attention architecture and evaluate its performance.</p>
<p>Data: I retrained the feedforward with attention model since my computer restarted and training was incomplete. I also modified the feedforward network so that it trains data from each time point separately as its own classification problem. While my model was training, I also worked on organizing my code and Jupyter notebook.</p>
<p>Files:</p>
<ul class="simple">
<li><p><a class="reference internal" href="hcp_data/ff.html"><span class="doc std std-doc">Feedforward Network</span></a></p></li>
<li><p><a class="reference internal" href="hcp_data/ff_attention.html"><span class="doc std std-doc">Feedforward Attention</span></a></p></li>
</ul>
<p><em>5:30 pm, 532 minutes</em></p>
<hr class="docutils" />
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Anna Gu<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>