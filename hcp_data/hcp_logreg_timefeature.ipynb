{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - (Time point, ROI) Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import scipy as scp\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dictionary into 2D Array\n",
    "def createData(movieDict):\n",
    "    # movieList = list(movieDict.keys())\n",
    "    # vals = list(movieDict.values())\n",
    "    \n",
    "    # Reduce to 2 dimensions\n",
    "    X = np.empty((176*18, 65*300+2), dtype=\"object\")\n",
    "\n",
    "    rCount = 0\n",
    "    for key, row in movieDict.items():\n",
    "        # Testretest\n",
    "        if len(row.shape) == 4:\n",
    "            for i in range(row.shape[0]):\n",
    "                for j in range(row.shape[-3]):\n",
    "                    X[rCount][-2] = 'testretest'\n",
    "                    X[rCount][-1] = j\n",
    "                    for k in range(65):\n",
    "                        for l in range(row.shape[-1]):\n",
    "                            X[rCount][k*row.shape[-1] + l] = row[i][j][k][l]\n",
    "                    rCount += 1\n",
    "                            \n",
    "        # Otherwise\n",
    "        else:\n",
    "            for j in range(row.shape[-3]):\n",
    "                X[rCount][-2] = key\n",
    "                X[rCount][-1] = j\n",
    "                for k in range(65):\n",
    "                    for l in range(row.shape[-1]):\n",
    "                        X[rCount][k*row.shape[-1] + l] = row[j][k][l]\n",
    "                rCount += 1\n",
    "                         \n",
    "    # Randomly split participants\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    index = np.arange(176)\n",
    "    np.random.shuffle(index)\n",
    "    testIndex = index[:76]\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    for row in X:\n",
    "        if row[-1] in testIndex:\n",
    "            X_test.append(row[:-2])\n",
    "            y_test.append(row[-2])\n",
    "        else:\n",
    "            X_train.append(row[:-2])\n",
    "            y_train.append(row[-2])\n",
    "\n",
    "    X_train = np.array(X_train).astype(float)\n",
    "    X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_test = np.array(X_test).astype(float)\n",
    "    X_test = (X_test - np.mean(X_test)) / np.std(X_test)\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HCP_movie_watching.pkl','rb') as f:\n",
    "    TS = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9678362573099415\n"
     ]
    }
   ],
   "source": [
    "# accList = []\n",
    "X_train, X_test, y_train, y_test = createData(TS)\n",
    "\n",
    "model = LogisticRegression(max_iter = 1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "acc = model.score(X_test, y_test)\n",
    "# accList.append(acc)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def cost(X, Y, W):\n",
    "    h = 1 / (1 + np.exp(-np.dot(X, W))) # hypothesis representation\n",
    "    cost = np.dot(Y, -np.log(h)) + np.dot((1-Y), np.log(1-h)) # cost function\n",
    "    J = -1 / (len(X)) * np.sum(cost) # mean cost\n",
    "    return J\n",
    "\n",
    "\n",
    "def gradient(X, Y, W):\n",
    "    h = 1 / (1 + np.exp(-np.dot(X, W)))\n",
    "    diff = h - Y\n",
    "    grad = 1 / (len(X)) * np.dot(diff, X)\n",
    "    return grad\n",
    "\n",
    "    \n",
    "def descent(X_train, Y_train, lr = 0.01):\n",
    "    weights = [0]*(len(X_train[0]))\n",
    "    loss = []\n",
    "    loss.append(cost(X_train, Y_train, weights))\n",
    "    count = 0\n",
    "    while count < 1000:\n",
    "        grad = gradient(X_train, Y_train, weights)\n",
    "        weights = weights - lr*grad\n",
    "        loss.append(cost(X_train, Y_train, weights))\n",
    "        count += 1\n",
    "\n",
    "    return weights\n",
    "\n",
    "def createYMask(movie, Y):\n",
    "    yMasked = np.zeros(Y.shape)\n",
    "    mask = Y == movie\n",
    "    yMasked[mask] = 1\n",
    "    return yMasked\n",
    "    \n",
    "def sigmoid(X, W):\n",
    "    return 1 / (1 + np.exp(-np.dot(X, W)))\n",
    "\n",
    "\"\"\"\n",
    "movieList = list(TS.keys())\n",
    "modelWeights = []\n",
    "for movie in movieList:\n",
    "    yMasked = createYMask(movie, y_train)\n",
    "    W = descent(X_train, yMasked)\n",
    "    modelWeights.append(W)\n",
    "predY = []\n",
    "for x in X_test:\n",
    "    probList = [sigmoid(x, W) for W in modelWeights]\n",
    "    predY.append(movieList[probList.index(max(probList))])\n",
    "\n",
    "pMask = y_test == predY # create mask for values where predicted is correct\n",
    "acc = sum(pMask) / len(pMask)\n",
    "print(acc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5d8d8f94dc29cf6517d9b951f40e6c965bcb2efc4a5d0d869ef8b359fa785960"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
