
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Feedforward Attention Summary &#8212; My Project</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Feedforward with Attention" href="ff_attention.html" />
    <link rel="prev" title="&lt;no title&gt;" href="attention-book.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">My Project</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Daily Log
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../table_of_contents.html">
   Table of Contents
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../entries.html">
   Entries
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep_work_entries.html">
     Prep Work
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../movie_watching_entries.html">
     Movie Watching fMRI Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../recurrent_nn_entries.html">
     Recurrent Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../encoder_decoder_entries.html">
     Seq2Seq Attention Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../ff_entries.html">
     Feedforward Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../transformers_entries.html">
     Transformers
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Prep Work
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../prep/deep_learning/deep_learning.html">
   Deep Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/deep_learning/dl_intro_notes.html">
     Intro
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/deep_learning/dl_tutorial1.html">
     Tutorial 1: Decoding Neural Responses
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/deep_learning/dl_tutorial1_code.html">
     Tutorial 1 Code
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/deep_learning/dl_tutorial2.html">
     Tutorial 2: Convolutional Neural Networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../prep/log_reg/logistic_regression.html">
   Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/log_reg/diabetes-logreg.html">
     Diabetes Prediction with Logistic Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../prep/log_reg/diabetes-summary.html">
     Diabetes Prediction Summary
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Movie Watching Dataset
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="hcp_summary.html">
   HCP Dataset
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="data.html">
     Visualization
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="hcp_logreg.html">
   HCP Logistic Regression
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="hcp_logreg_indivtime.html">
     Logistic Regression - ROI Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="hcp_logreg_permtest.html">
     Permutation Test
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../multiple_inference.html">
   Multiple Inference
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Neural Networks
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="ff_summary.html">
   Feedforward Summary
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="ff.html">
     Feedforward Neural Network
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../recurrent_nn.html">
   Recurrent Neural Network Notes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Attention
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="attention_methods.html">
   Attention Methods
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="simple">
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   Feedforward Attention Summary
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="ff_attention.html">
     Feedforward with Attention
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="gru_attention.html">
   GRU Attention Model
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="transformers_summary.html">
   Transformers Summary
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="transformer.html">
     Single-head and Single-layer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transformer_multihead.html">
     Multi-head and Multilayer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="transformer_position.html">
     Position Encoding
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/hcp_data/ff_attention_summary.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-creation">
   Dataset Creation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feedforward-neural-network">
   Feedforward Neural Network
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention">
   Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-inputs">
   Random Inputs
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Feedforward Attention Summary</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-creation">
   Dataset Creation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feedforward-neural-network">
   Feedforward Neural Network
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#attention">
   Attention
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-inputs">
   Random Inputs
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="feedforward-attention-summary">
<h1>Feedforward Attention Summary<a class="headerlink" href="#feedforward-attention-summary" title="Permalink to this headline">#</a></h1>
<p>A feedforward neural network with attention was applied to the HCP dataset for 15-way time series classification of movie clips. Code can be found <a class="reference internal" href="ff_attention.html"><span class="doc std std-doc">here</span></a>.</p>
<p>Dimensions of the data were used for the following purposes:</p>
<ul class="simple">
<li><p>Movie name - apply as label for classification</p></li>
<li><p>ROI - use as features for classification</p></li>
<li><p>Subject - split into training and testing sets</p></li>
<li><p>Time point - categorize model results as time series of accuracies</p></li>
</ul>
<section id="dataset-creation">
<h2>Dataset Creation<a class="headerlink" href="#dataset-creation" title="Permalink to this headline">#</a></h2>
<p>The dataset was transformed from a dictionary with movie clip names as keys and arrays of fMRI data as values (see <a class="reference internal" href="hcp_summary.html"><span class="doc std std-doc">summary</span></a>) to 3-dimensional arrays of X- and Y- train and test sets. Only the first 90 seconds, equivalent to the first 90 time points, were used.</p>
<p>The data was split with 100 participants for training and 76 participants for testing. A list of participants used for the testing data set was randomly generated. Participant numbers within this list had corresponding ROI feature data and movie labels stored in a testing dictionary. The same was done for participants not selected in the test set, except with a training dictionary. Dimensions for the values of these dictionaries were the same as the in the original dataset, except for ‘testretest’ cases, different runs from the same subject were also compiled as separate batches, converting 4 dimensions to 3.</p>
<p>For each dictionary, 3-dimensional arrays were created containing data across all of the first 90 time points. ROI input data was stored in an X_train or X_test array while movie labels were stored in a y_train or y_test array. ROI feature data was normalized with z-scores, and movie clip labels were one-hot encoded for each time step. Batches with less than 90 time steps were padded with 0.0. Thus, the X input sets had dimensions (batches, time steps = 90, features = 300) and the y label sets had dimensions (batches, time steps = 90, movie clips = 15).</p>
<p>The training datasets and testing datasets were wrapped into tensors to input into the model.</p>
</section>
<section id="feedforward-neural-network">
<h2>Feedforward Neural Network<a class="headerlink" href="#feedforward-neural-network" title="Permalink to this headline">#</a></h2>
<p>A feedforward architecture was created using PyTorch. The model consisted of an input layer, a fully connected hidden layer, an attention layer, and another fully connected output layer, as pictured below. The movie corresponding to the index of the maximum value of the 15-dimensional output vector was the predicted label. Padded values were not masked.</p>
<p><img alt="" src="../_images/ff_neural_network_attention.drawio.png" /></p>
<p>The model was fitted using the X_train set as input and the y_train set as output across all considered time points. Time points are considered blindly, so the training set consists of 300-dimensional input vectors from all 100 train participants and across all 90 time points considered. The Adam optimizer and cross-entropy loss function were used in training. Learning rate was set to 0.01 and epochs were set to 5.</p>
<p>The model was then evaluated with the testing data at all 90 time points, and the accuracy was saved. Classification accuracy at each time point was plotted.</p>
</section>
<section id="attention">
<h2>Attention<a class="headerlink" href="#attention" title="Permalink to this headline">#</a></h2>
<p>The attention layer inputted the output from the previous fully connected hidden layer, of dimensions (batches, time steps = 90, hidden = 32) and outputted 32-dimensional context vectors for each time step of dimensions. The vectors were repeated across all batches, so the final dimensionality of the output from attention was (batches, time steps = 90, hidden = 32). Here, all time steps <span class="math notranslate nohighlight">\(1\)</span> through <span class="math notranslate nohighlight">\(T=90\)</span> were accessible by all other time steps.</p>
<p>Context vectors were calculated as the final output of the attention mechanism and expressed the relationship between hidden layer outputs for different time steps. The process below is described for an individual batch. The methods were replicated across all batches in the dataset, such that the same parameters and weight vectors/matrices were used.</p>
<p>A matrix <span class="math notranslate nohighlight">\(e\)</span> of dimensions (time steps = 90, time steps = 90) was calculated. Each element <span class="math notranslate nohighlight">\(e_{ij}\)</span> was calculated using the following equation:</p>
<div class="math notranslate nohighlight">
\[
e_{ij} = \boldsymbol{V}_{a} ^{T} \tanh(\boldsymbol{W}_{a}h_{i} + \boldsymbol{U}_{a}h_{j}),
\]</div>
<p>where <span class="math notranslate nohighlight">\(h_i\)</span> and <span class="math notranslate nohighlight">\(h_j\)</span> are hidden layer outputs at time steps <span class="math notranslate nohighlight">\(1 \le i,j \le 90\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{V}_{a} ^{T}\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{W}_{a}\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{U}_{a}\)</span> are weight matrices/parameters for the attention layer. Considering an individual batch (i.e. ignoring the first dimension), <span class="math notranslate nohighlight">\(h_i\)</span> and <span class="math notranslate nohighlight">\(h_j\)</span> are 32-dimensional vectors. <span class="math notranslate nohighlight">\(\boldsymbol{W}_{a}\)</span> and <span class="math notranslate nohighlight">\(\boldsymbol{U}_{a}\)</span> are (hidden = 32, hidden = 32) matrices; in practice, they are implemented as linear, fully connected layers with input and output dimensions as ((*, hidden = 32), (*, hidden = 32)).</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{V}_{a}^{T}\)</span> is a horizontal vector of dimensions (1, hidden = 32). Performing matrix multiplication on <span class="math notranslate nohighlight">\(\boldsymbol{V}_{a}^{T}\)</span> and the matrix from the <span class="math notranslate nohighlight">\(\tanh\)</span> function of dimensions (hidden = 32, 1) results in scalar <span class="math notranslate nohighlight">\(e_{ij}\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{V}_{a} ^{T}\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{W}_{a}\)</span>, and <span class="math notranslate nohighlight">\(\boldsymbol{U}_{a}\)</span> are parameters of the feedforward model, so they are fitted through backpropagation and the loss function and optimizer used to train the other layers.</p>
<p>The <span class="math notranslate nohighlight">\(e\)</span> matrix is used to calculated a matrix of attnetion scores, <span class="math notranslate nohighlight">\(\alpha\)</span>, by passing each element in <span class="math notranslate nohighlight">\(e\)</span> through the <span class="math notranslate nohighlight">\(softmax\)</span> function:</p>
<div class="math notranslate nohighlight">
\[
\alpha_{ij} = \frac {\exp(e_{ij})} {\Sigma_{k=1} ^{T=90} exp(e_{ik})}
\]</div>
<p>Then, the context vector for each time step <span class="math notranslate nohighlight">\(1 \le i \le 90\)</span> is calculated using (time steps = 90, time steps = 90) matrix <span class="math notranslate nohighlight">\(\alpha\)</span> and the outputs from the hidden layer:</p>
<div class="math notranslate nohighlight">
\[
c_{i} = \Sigma _{j=1} ^{T} \alpha_{ij} h_{j}
\]</div>
</section>
<section id="random-inputs">
<h2>Random Inputs<a class="headerlink" href="#random-inputs" title="Permalink to this headline">#</a></h2>
<p>Random inputs based on the normal distribution were generated 20 times to fill the X_test dataset of dimensions (batches, time steps = 90, features = 300). The fitted feedforward attention model was applied to each of the randomly generated datasets, and a classification accuracy was calculated. The accuracy obtained from testing the model on the original dataset and the 90th percentile of accuracies obtained from random inputs were compared as time series:</p>
<p><img alt="" src="../_images/ff_attention_accuracy.png" /></p>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./hcp_data"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="attention-book.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">&lt;no title&gt;</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="ff_attention.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Feedforward with Attention</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Anna Gu<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>